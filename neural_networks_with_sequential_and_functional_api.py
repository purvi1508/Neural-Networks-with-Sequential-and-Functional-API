# -*- coding: utf-8 -*-
"""Neural Networks with Sequential and Functional API

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1974w7d_drRhPvEDqj3nXT3JRxRbOe0A1
"""

import tensorflow as tf
print("TensorFlow version:", tf.__version__)

x=tf.constant([[1,2,3],[4,5,6]])
print(x)

tf.eye(3) #identity matrix

x=tf.random.normal((3,3),mean=0,stddev=1)

x=tf.random.uniform((1,3),minval=0,maxval=3)

x=tf.range(start=1,limit=10,delta=2)

#mathematical operations
x=tf.constant([1,2,3])
y=tf.constant([9,8,7])

z=tf.add(x,y)
print(z)

z=x*y
print(z)

z=tf.tensordot(x,y,axes=1)
#z=tf.reduce_sum(x*y,axis=0)

#element vise multiplication
z=x**5

x=tf.random.normal((2,3))
y=tf.random.normal((3,4))
z=tf.matmul(x,y)
#z=x@y
print(z)

from tensorflow import keras

from tensorflow.keras import layers
from tensorflow.keras.datasets import mnist

(x_train,y_train),(x_test,y_test)=mnist.load_data()

x_train = x_train.reshape(-1,28*28).astype("float32")/255.0
x_test = x_test.reshape(-1,28*28).astype("float32")/255.0
#flatten then so that we would have only one long column
#they are going to be numpy arrays float64

#using sequential API of keras to crate basic neural network
#(very convenient but not very flexible)=> one input mapped to only one output
model = tf.keras.models.Sequential([
  tf.keras.layers.Dense(512, activation='relu'),
  tf.keras.layers.Dense(256, activation='relu'),
  tf.keras.layers.Dense(10, activation='relu'),
])

#how to configure the training part of our network
#The Softmax activation function calculates the relative probabilities
#since we don't have softmax activation 
model.compile(
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), #learning rate
    metrics=["accuracy"]
)

#concrete training of the network
model.fit(x_train,y_train,batch_size=32, epochs=5, verbose=2)
model.evaluate(x_train,y_train,batch_size=32, verbose=2)

#if we specify input first of all
model = tf.keras.models.Sequential([
  keras.Input(shape=(28*28)),
  tf.keras.layers.Dense(512, activation='relu'),
  tf.keras.layers.Dense(256, activation='relu'),
  tf.keras.layers.Dense(10, activation='relu'),
])
#we could actually do
print(model.summary())
#we would be able to see information about the network

#Functional API its a bit more flexible
#handle multiple inputs and multiple outputs 
input=keras.Input(shape=(784))
x= tf.keras.layers.Dense(512, activation='relu')(input)
x= tf.keras.layers.Dense(256, activation='relu')(x)
output = tf.keras.layers.Dense(10, activation='softmax')(x)

model=keras.Model(inputs=input, outputs=output)

model.compile(
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), #learning rate
    metrics=["accuracy"]
)
#since we have defined softmax in output layer, from_logits=False

#concrete training of the network
model.fit(x_train,y_train,batch_size=32, epochs=5, verbose=2)
model.evaluate(x_train,y_train,batch_size=32, verbose=2)

